{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training RL Model on SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to train a reinforcement learning (RL) model using SageMaker. We'll initialize the SageMaker session, set up the environment for training, define the necessary S3 bucket and Docker image, and then proceed with the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.session import get_execution_role\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing essential libraries:\n",
    "\n",
    "- boto3 and sagemaker are used to interact with AWS services.\n",
    "- Estimator, Session, and get_execution_role are required for setting up the SageMaker environment.\n",
    "- os and time are standard Python libraries for system operations and time tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize SageMaker Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we initialize the SageMaker session and retrieve the appropriate execution role using get_execution_role().\n",
    "- The S3 bucket is where the model artifacts will be stored.\n",
    "- The ecr_image_uri is the URI of the Docker image that contains the RL environment and is stored in Elastic Container Registry (ECR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below change \"my-account-id\" for you actual account ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Get the execution role for SageMaker\n",
    "role = get_execution_role()\n",
    "\n",
    "# Define your S3 bucket and prefixes\n",
    "s3_bucket = 'traffic-opimization-<my-account-id>-us-east-1'\n",
    "\n",
    "# Define the Docker image URI from ECR\n",
    "ecr_image_uri = 'deep-q-learning-model-<my-account-id>-us-east-1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the environment variables that will be passed to the training script.\n",
    "- PROCESS_TYPE is set to 'TRAIN' to specify that the job is for training.\n",
    "- The S3_BUCKET is provided as part of the environment to store training artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables for training\n",
    "train_env = {\n",
    "    'PROCESS_TYPE': 'TRAIN',\n",
    "    'S3_BUCKET': s3_bucket\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a good RL model takes a while, so before we run our smaller 10 episode model, let's view the output plots of the model that we will be using later for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Function to list and display images from S3\n",
    "def display_s3_images(bucket, prefix):\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "    if 'Contents' in response:\n",
    "        for obj in response['Contents']:\n",
    "            key = obj['Key']\n",
    "            if key.endswith('.png'):  # Filter for PNG images\n",
    "                print(f\"Displaying image: {key}\")\n",
    "                \n",
    "                # Get the image from S3\n",
    "                img_obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "                img_data = img_obj['Body'].read()\n",
    "                \n",
    "                # Display the image using PIL and matplotlib\n",
    "                image = Image.open(io.BytesIO(img_data))\n",
    "                plt.figure()\n",
    "                plt.imshow(image)\n",
    "                plt.axis('off')  # Hide the axes\n",
    "                plt.title(key)\n",
    "                plt.show()\n",
    "    else:\n",
    "        print(f'No objects found in s3://{bucket}/{prefix}')\n",
    "\n",
    "# Define the S3 bucket and prefix for the folder\n",
    "s3_prefix = 'trained_model_plots/'  # Folder where the images are stored\n",
    "\n",
    "# Display images from the oldplots/ folder\n",
    "display_s3_images(s3_bucket, s3_prefix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to train our own model. \n",
    "\n",
    "We create an RL Estimator, which is a SageMaker-specific class used for training RL models. Key parameters include:\n",
    "\n",
    "- entry_point: The Python script that will be executed to start the training.\n",
    "- image_uri: The Docker image URI containing the RL environment.\n",
    "- toolKit and toolkit_version: Specify the RL toolkit and its version (Coach in this case).\n",
    "- framework: Defines the machine learning framework (TensorFlow).\n",
    "- instance_type: Specifies the type of EC2 instance for training (a GPU-enabled instance in this case).\n",
    "- environment: The environment variables, including the S3 bucket and process type.\n",
    "- instance_count: Specifies how many instances to use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework\n",
    "\n",
    "rl_estimator = RLEstimator(\n",
    "    entry_point=\"sagemaker_train.py\",  # Adjust to your script name\n",
    "    image_uri=ecr_image_uri,\n",
    "    toolkit=RLToolkit.COACH,\n",
    "    toolkit_version='0.11.1',\n",
    "    framework=RLFramework.TENSORFLOW,\n",
    "    role=role,\n",
    "    instance_type='ml.c5.4xlarge',\n",
    "    instance_count = 1,\n",
    "    environment=train_env,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training job\n",
    "rl_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our plots vs the trained model ones. You can see that the delay is still alot bigger if we just use 10 episodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_prefix_10ep_model = 'plots/'\n",
    "\n",
    "display_s3_images(s3_bucket, s3_prefix_10ep_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
